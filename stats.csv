Network Type,Dataset,accuracy,f1_sc,train_time,test_time
Naive Bayes,Combined,0.5528971962616822,0.46640056467172447,4.092968225479126,0.00040588343254873685
Naive Bayes,Reddit,0.5130765572990965,0.4260236555425486,4.493332862854004,0.0003810747984413789
Linear SVC,Combined,0.5293457943925234,0.5165011874905696,5.2322094440460205,0.00039224633546633143
Linear SVC,Reddit,0.5130765572990965,0.5091116983155257,5.636647701263428,0.0004150156217200734
Simple NN,Combined,0.7667289972305298,0.7666441493835334,26.03896450996399,0.0005601376685026651
Simple NN,Reddit,0.82406085729599,0.8235869452843159,15.202148914337158,0.0004853236118209696
Simple NN with dropout,Combined,0.7857943773269653,0.7854946208344267,25.33116102218628,0.0005180650336720119
Simple NN with dropout,Reddit,0.7998098134994507,0.7994898940178048,15.415280818939209,0.0005052853521899642
Simple NN with Batch Norm,Combined,0.7798131108283997,0.7797479530675087,18.06488347053528,0.0005236831558084933
Simple NN with Batch Norm,Reddit,0.8012363314628601,0.8012352054816823,16.534130096435547,0.0005702098953389676
Simple RNN,Combined,0.7854205369949341,0.7853838197472884,429.66085934638977,0.0008015777017468604
Simple RNN,Reddit,0.828340470790863,0.8281911348532904,336.3836793899536,0.0007044618374833437
Simple RNN with dropout,Combined,0.8048598170280457,0.804758285346112,439.41459250450134,0.0007922898943179122
Simple RNN with dropout,Reddit,0.8388017416000366,0.8387871310469496,330.7103099822998,0.0007368626104337033
Simple RNN with Batch Norm,Combined,0.7188785076141357,0.7184279894560268,426.89064931869507,0.0007889867051739559
Simple RNN with Batch Norm,Reddit,0.8316690325737,0.8311641716847524,390.53990030288696,0.000715701201251734
LSTM,Combined,0.8003738522529602,0.8003434464513143,30.206917762756348,0.0006814798016414464
LSTM,Reddit,0.8368996381759644,0.8367187607875486,24.867677450180054,0.0006732026216025664
LSTM with dropout,Combined,0.8037382960319519,0.8029424455131915,30.59602117538452,0.0007957476321781907
LSTM with dropout,Reddit,0.8235853314399719,0.8234218163440958,25.916876316070557,0.0007019878102240162
LSTM with Batch Norm,Combined,0.793271005153656,0.7926533599820249,47.160775899887085,0.0008892201040392725
LSTM with Batch Norm,Reddit,0.8454588651657104,0.8454499222472742,33.62095546722412,0.0006787078180045725
Bi-LSTM,Combined,0.8071027994155884,0.8070212230517575,44.46635341644287,0.0008469850771895079
Bi-LSTM,Reddit,0.8407037854194641,0.8407001545955022,35.62859296798706,0.0008821752138226946
Bi-LSTM with dropout,Combined,0.8078504800796509,0.8076993006993007,44.81594634056091,0.0008315471399610287
Bi-LSTM with dropout,Reddit,0.8292914628982544,0.8287523377152144,37.00762987136841,0.0008820826093727183
Bi-LSTM with Batch Norm,Combined,0.8104673027992249,0.8101462513255011,45.43944549560547,0.0008792157930748484
Bi-LSTM with Batch Norm,Reddit,0.8549690842628479,0.8549685670827045,38.21675777435303,0.000814019408181449
GRU,Combined,0.797383189201355,0.7969108769539195,47.84619355201721,0.0007742374634074273
GRU,Reddit,0.8288159966468811,0.828620634702171,25.862921714782715,0.0006473541259765625
GRU with dropout,Combined,0.8044859766960144,0.8034946151604216,32.70288443565369,0.0007787615339332652
GRU with dropout,Reddit,0.844032347202301,0.8439332096474954,27.725364446640015,0.0006613933705837927
GRU with Batch Norm,Combined,0.8007476925849915,0.7997373420277336,33.368208169937134,0.0008115501047294831
GRU with Batch Norm,Reddit,0.8297669887542725,0.829238452954465,33.893587827682495,0.0006444170764673536
Bi GRU,Combined,0.8074766397476196,0.80733705795209,48.14734077453613,0.000875734347049321
Bi GRU,Reddit,0.8464099168777466,0.8464098906324299,48.732112884521484,0.0008559907039749289
Bi GRU with dropout,Combined,0.7925233840942383,0.7919856850002291,48.47433066368103,0.0008591191122465045
Bi GRU with dropout,Reddit,0.8525915145874023,0.8525912359245693,49.10359215736389,0.0007741471762969115
Bi GRU with Batch Norm,Combined,0.8048598170280457,0.8045109687217551,49.36493706703186,0.0008736827885993173
Bi GRU with Batch Norm,Reddit,0.800760805606842,0.7998222574799408,57.39518117904663,0.0007842191357478917
Conv Stacked,Combined,0.7719626426696777,0.771851629385538,33.79853129386902,0.0005753119638033002
Conv Stacked,Reddit,0.82406085729599,0.8240359983211156,15.308107376098633,0.0005592848875812281
Conv,Combined,0.7685981392860413,0.7685514246843907,25.15725088119507,0.0005609437461211302
Conv,Reddit,0.8107465505599976,0.8105974753390262,14.0544273853302,0.0005664835243581612
Conv with dropout,Combined,0.7940186858177185,0.7928373742642296,25.708109617233276,0.0005745602545337142
Conv with dropout,Reddit,0.8430812954902649,0.8430625407048267,15.87567400932312,0.0005089818651431075
Conv with Batch Norm,Combined,0.7955140471458435,0.7954882961958705,17.681037664413452,0.0005277860944516191
Conv with Batch Norm,Reddit,0.8407037854194641,0.8406621081350407,25.854609727859497,0.0005635233905827888
