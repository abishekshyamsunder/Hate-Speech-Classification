Network Type,Dataset,accuracy,f1_sc,train_time,test_time
Naive Bayes,Combined,0.5528971962616822,0.46640056467172447,7.7817559242248535,0.0007001929416834751
Naive Bayes,Reddit,0.5130765572990965,0.4260236555425486,7.741987943649292,0.0006075950872118228
Linear SVC,Combined,0.5293457943925234,0.5165011874905696,8.66455602645874,0.0006411779706723222
Linear SVC,Reddit,0.5130765572990965,0.5091116983155257,8.543373823165894,0.0006004796963985836
Simple NN,Combined,0.7667289972305298,0.7666441493835334,23.270818948745728,0.000766222766626661
Simple NN,Reddit,0.82406085729599,0.8235869452843159,29.182952880859375,0.0014693637206175617
Simple NN with dropout,Combined,0.7854205369949341,0.7852937886287998,29.628965854644775,0.0008147491918546017
Simple NN with dropout,Reddit,0.7988587617874146,0.7979889021735798,19.024781942367554,0.0008538343304785612
Simple NN with Batch Norm,Combined,0.7764486074447632,0.7763470488687955,22.493143796920776,0.0007739442308372426
Simple NN with Batch Norm,Reddit,0.800760805606842,0.8007579346281383,30.017683744430542,0.0011943786835002007
Simple RNN,Combined,0.7697196006774902,0.7694644322148763,140.1928870677948,0.001042272175583884
Simple RNN,Reddit,0.8530670404434204,0.8530084180739202,151.03820085525513,0.0009807181135516301
Simple RNN with dropout,Combined,0.7940186858177185,0.7940182310129019,150.50085496902466,0.0010251277852281232
Simple RNN with dropout,Reddit,0.8311935067176819,0.8311860515967189,150.90952014923096,0.00095841078000648
Simple RNN with Batch Norm,Combined,0.7095327377319336,0.7090758915842909,136.45368337631226,0.001099846474478178
Simple RNN with Batch Norm,Reddit,0.8311935067176819,0.8311715448527861,154.83003687858582,0.000954360338014977
LSTM,Combined,0.8018691539764404,0.8017294811165074,199.15268087387085,0.0013356078673745985
LSTM,Reddit,0.835948646068573,0.8358558578532792,156.84724879264832,0.0014093940057487131
LSTM with dropout,Combined,0.800000011920929,0.7999888193592795,204.85579228401184,0.0014050112038015204
LSTM with dropout,Reddit,0.8483119606971741,0.8483117981370707,158.3539879322052,0.0013336519437415577
LSTM with Batch Norm,Combined,0.8048598170280457,0.8044463577880305,203.7561867237091,0.0014302194007089204
LSTM with Batch Norm,Reddit,0.8212078213691711,0.8206139427509456,220.21465396881104,0.0010845270780759438
Bi-LSTM,Combined,0.8011214733123779,0.8009890832772095,393.4802680015564,0.0015235014050920433
Bi-LSTM,Reddit,0.8326200842857361,0.8322632103688934,336.9975118637085,0.0016350302295150044
Bi-LSTM with dropout,Combined,0.8085981011390686,0.8085724221291175,297.42067980766296,0.002251641817182024
Bi-LSTM with dropout,Reddit,0.8292914628982544,0.8286366621127269,238.69431900978088,0.001411283261308046
Bi-LSTM with Batch Norm,Combined,0.8085981011390686,0.8083356097211463,302.87346482276917,0.0017760452377461942
Bi-LSTM with Batch Norm,Reddit,0.82406085729599,0.8234957064254813,277.2938199043274,0.001791187714193469
